- LLM tool used: ChatGPT.
- Reason: Since I'm not that well-versed with all the possibilities of Docker, I used ChatGPT to help debug the docker-compose.yaml problems and customize the images' behavior with their Dockerfile. 
- How it helped: First, I tried to create the Dockerfile and docker-compose file based on what I learned in the previous courses. However, I had some problems, and ChatGPT helped me diagnose and fix them. For example, I was using the wrong URL in service1 to fetch information from service2 (it should be "http://service2:5000", but I put it to be "http://127.0.0.1:5000" in the beginning). It also helped me with some async/await syntax in my app.js file and showed me how to test the images individually through the CLI.
- What kind of mistakes did LLM make? It didn't understand what I wanted when I asked if it was possible to get the IP address of the running container from within the service. It told me to use Docker's CLI to fetch that, but it isn't possible to fetch that from the container's kernel. 
- What were things that LLM could not provide? I would say anything unrelated to "technical" or "syntactic" stuff, so any high-level and structural things about the services. That's why I only asked it to help me debug the details and syntax errors, but not when building the services themselves.